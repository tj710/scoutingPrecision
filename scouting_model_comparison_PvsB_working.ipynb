{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'SDK-tjames')\n",
    "import os\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Input, Reshape, Concatenate, Dense\n",
    "from keras.models import Model, model_from_json\n",
    "import onnx\n",
    "import onnxmltools\n",
    "import fwdnxt\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import onnxruntime\n",
    "#from qkeras import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_pairs_dataset(df_pairs):\n",
    "    df_pairs['remove_row'] = [True if abs(phi_r_even - phi_r_odd) < 0.0001 else False \\\n",
    "                              for phi_r_even, phi_r_odd in zip(df_pairs['phi_r'], df_pairs['phi_r'].shift())]\n",
    "    \n",
    "    indices_to_exclude = df_pairs.index[(df_pairs['remove_row'] == True) | \\\n",
    "                            (df_pairs['pt_r'] < 2.5) | (df_pairs['pt_r'] > 45) | \\\n",
    "                            (df_pairs['eta_r'] < -2.45) | (df_pairs['eta_r'] > 2.45) | \\\n",
    "                            (df_pairs['eta_e'] < -2.45) | (df_pairs['eta_e'] > 2.45)].tolist()\n",
    "    \n",
    "    indices_to_exclude = set(indices_to_exclude)\n",
    "    additional_odd = set([x + 1 for x in indices_to_exclude if x % 2 == 0])\n",
    "    additional_even = set([x - 1 for x in indices_to_exclude if x % 2 == 1])\n",
    "    indices_to_exclude.update(additional_odd)\n",
    "    indices_to_exclude.update(additional_even)\n",
    "    \n",
    "    clean_df = df_pairs.drop(indices_to_exclude)\n",
    "    \n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_moun_dataset(filename):\n",
    "    muon_pairs_dataset = pd.read_hdf(filename)\n",
    "\n",
    "    if 'phi' in muon_pairs_dataset.columns:\n",
    "        muon_pairs_dataset.rename(inplace=True, \n",
    "                                  columns={'phi':'phi_r','phie':'phi_e','eta':'eta_r','etae':'eta_e','pt':'pt_r'})\n",
    "\n",
    "    has_true = False\n",
    "    if set(['phi_t','eta_t','pt_t']).issubset(muon_pairs_dataset.columns):\n",
    "        has_true = True\n",
    "\n",
    "    return clear_pairs_dataset(muon_pairs_dataset), has_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    json_file = open(model_name + '.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    model.load_weights(model_name + '.h5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from one output get 3 outputs (phi, eta, pt)\n",
    "def parse_board_results(result, imgs_per_cluster, outputs):\n",
    "    phi = np.array([x for i, x in enumerate(result) if i % outputs == 0])\n",
    "    eta = np.array([x for i, x in enumerate(result) if (i - 1) % outputs == 0])\n",
    "    pt = np.array([x for i, x in enumerate(result) if (i - 2) % outputs == 0])\n",
    "        \n",
    "    return phi, eta, pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_board(X_pairs, model_filepath, imgs_per_cluster=1000, sw=False):\n",
    "    phi = []\n",
    "    eta = []\n",
    "    pt = []\n",
    "    \n",
    "    iterations = int(len(X_pairs) / imgs_per_cluster)\n",
    "    \n",
    "    #f= open(\"ie_20Events_output_withoutV.txt\",\"w+\")\n",
    "    \n",
    "    ie = fwdnxt.FWDNXT()\n",
    "    ie.SetFlag('debug', 'wbn')\n",
    "    # variable length\n",
    "    ie.SetFlag(\"options\", \"V\")\n",
    "    ie.SetFlag('imgs_per_cluster', str(imgs_per_cluster))\n",
    "    swnresults = ie.Compile('4x1x1', model_filepath, 'save.bin', 1, 1)\n",
    "    nresults = ie.Init('save.bin', '')\n",
    "    result = np.ndarray(swnresults, dtype=np.float32)\n",
    "    \n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    for iter_i in range(0, len(X_pairs), imgs_per_cluster):\n",
    "        start = iter_i\n",
    "        end = start + imgs_per_cluster\n",
    "        print(iter_i)\n",
    "        print(start)\n",
    "        print(end)\n",
    "        \n",
    "        current_batch = np.ascontiguousarray(np.swapaxes(np.expand_dims(\\\n",
    "                            np.expand_dims(X_pairs[start:end, :], 0), 0), 0, 2), dtype=np.float32())\n",
    "        print(current_batch.shape)\n",
    "        print(current_batch[0][0][0])\n",
    "        \n",
    "        sess = onnxruntime.InferenceSession(model_filepath)\n",
    "        input_name = sess.get_inputs()[0].name\n",
    "        output_name = sess.get_outputs()[0].name\n",
    "        Y_out = np.array(sess.run([output_name], {input_name: current_batch}))\n",
    "        Y_out = np.squeeze(Y_out, axis = 0)\n",
    "        if(current_batch.shape != (1000, 1, 1, 4)): break\n",
    "        \n",
    "        result = np.ndarray(swnresults, dtype=np.float32)\n",
    "        print(result.shape)\n",
    "        ie.Run_sw(current_batch, result)\n",
    "        #print(\"output onnxruntime = \", Y_out)\n",
    "        #print(Y_out.shape)\n",
    "        cur_phi_pred, cur_eta_pred, cur_pt_pred = parse_board_results(result, imgs_per_cluster, outputs=3)\n",
    "        phi.extend(cur_phi_pred)\n",
    "        eta.extend(cur_eta_pred)\n",
    "        pt.extend(cur_pt_pred)\n",
    "        sw_result = []\n",
    "        for p, e, p_t in zip(cur_phi_pred, cur_eta_pred, cur_pt_pred):\n",
    "            sw_result.append([p,e,p_t])\n",
    "        #print(\"output sw = \", sw_result)\n",
    "        #print(len(sw_result))\n",
    "        #print()\n",
    "        #f.write(\"iter=\"+str(iter_i)+\"\\n\")\n",
    "        #f.write(\"Inputs: \"+str(current_batch[0][0][0])+\"\\n\")\n",
    "        #f.write(\"output onnxruntime = \" + str(Y_out)+\"\\n\")\n",
    "        #f.write(\"output MicronDLA = \" + str(sw_result)+\"\\n\")\n",
    "        #f.write(\"===================================\"+\"\\n\")\n",
    "        #if iter_i == 200: break\n",
    "        \n",
    "    ie.Free()\n",
    "     \n",
    "    return phi, eta, pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta_phi(phi_approx, phi_true):\n",
    "    return np.array([x - 2*math.pi if x > math.pi else x + 2*math.pi if x < -math.pi else x for x in phi_approx - phi_true])\n",
    "\n",
    "def calculate_phi(phi_approx, delta_phi):\n",
    "    \"\"\"array = []\n",
    "    for approx, dphi in zip(phi_approx, delta_phi):\n",
    "        array.append(approx - dphi)\n",
    "    array = np.reshape(array, (len(array),1))\"\"\"\n",
    "    return np.array([x - 2*math.pi if x > math.pi else x + 2*math.pi if x < -math.pi else x for x in phi_approx - delta_phi])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(values):\n",
    "    print(np.min(values), np.max(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'integer_scouting_7_4_2020_3layers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_per_cluster = 1000\n",
    "n = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#muon_pairs_dataset, _ = read_moun_dataset('datasets/scout_325172.hd5')\n",
    "#muon_pairs_dataset = pd.read_csv('train_set_tight.csv')\n",
    "#muon_pairs_dataset = muon_pairs_dataset[:n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if quality is always the same\n",
    "def check_quality(dataset):\n",
    "    if (dataset['qual'] == 12).all(): return True\n",
    "    else:\n",
    "        print(dataset[dataset['qual'] != 12]['qual'].shape)\n",
    "        return False\n",
    "\n",
    "#print(check_quality(muon_pairs_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_integer_values_to_df(df_base):\n",
    "    #new_phi_r = np.array([x if x > 0 else x + 2*math.pi for x in df_base['phi_r']])\n",
    "    new_phi_e = np.array([x if x > 0 else x + 2*math.pi for x in df_base['phiVtxL1']])\n",
    "    \n",
    "    #df_base['int_phi_r'] = (new_phi_r / (2*math.pi / 576)).astype(int)\n",
    "    df_base['int_phi_e'] = (new_phi_e / (2*math.pi / 576)).astype(int)\n",
    "    \n",
    "    #df_base['int_eta_r'] = (df_base['eta_r'] / 0.010875).astype(int)\n",
    "    df_base['int_eta_e'] = (df_base['etaVtxL1'] / 0.010875).astype(int)\n",
    "\n",
    "    df_base['int_pt_r'] = (df_base['pTL1'] / 0.5).astype(int)\n",
    "    return df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#muon_pairs_dataset = add_integer_values_to_df(muon_pairs_dataset)\n",
    "\n",
    "#print_stats(muon_pairs_dataset['int_phi_e'])\n",
    "#print_stats(muon_pairs_dataset['int_eta_e'])\n",
    "#print_stats(muon_pairs_dataset['int_pt_r'])\n",
    "#print_stats(muon_pairs_dataset['charge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pairs = pd.read_csv('mu_barrel_tight_zb2018D.csv', index_col=False, delimiter=',')\n",
    "X_pairs = add_integer_values_to_df(X_pairs)\n",
    "X_pairs = np.array(X_pairs[[ 'int_phi_e','int_eta_e','int_pt_r','charge']])\n",
    "\n",
    "X_scaler = joblib.load('integer_scouting_7_4_2020_3layers_X_scaler.dat')\n",
    "X_test = X_scaler.transform(X_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_python(X_pairs, model):\n",
    "    Y_out = model.predict(X_pairs, batch_size=1024)\n",
    "    \n",
    "    phi = Y_out[0]\n",
    "    eta = Y_out[1]\n",
    "    pt = Y_out[2]\n",
    "    \n",
    "    return phi, eta, pt\n",
    "\n",
    "def reconstruct_original_values(muon_pairs_dataset, \\\n",
    "                                delta_phi_pred_delta_pairs, delta_eta_pred_delta_pairs, delta_pt_pred_delta_pairs):\n",
    "    phi_pred_delta_pairs = calculate_phi(muon_pairs_dataset['phi_e'], delta_phi_pred_delta_pairs)    \n",
    "    eta_pred_delta_pairs = np.array(muon_pairs_dataset['eta_e'] - delta_eta_pred_delta_pairs)\n",
    "    pt_pred_delta_pairs = np.array(muon_pairs_dataset['pt_r'] - delta_pt_pred_delta_pairs)\n",
    "    \n",
    "    return phi_pred_delta_pairs, eta_pred_delta_pairs, pt_pred_delta_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_phi_python, delta_eta_python, delta_pt_python = get_predictions_python(X_test, model)\n",
    "#y_predicted = get_predictions_python(X_pairs, model)\n",
    "#print(y_predicted.shape)\n",
    "delta_phi_python = np.squeeze(delta_phi_python)\n",
    "delta_eta_python = np.squeeze(delta_eta_python)\n",
    "delta_pt_python = np.squeeze(delta_pt_python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"X_test = pd.read_csv('test_overlap_data_17_4.csv', names=['int_phi_e', 'int_eta_e', 'int_pt_r', 'charge'])\n",
    "X_test = np.array(X_test[['int_phi_e', 'int_eta_e', 'int_pt_r', 'charge']])\n",
    "print(X_test)\n",
    "print(X_test.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_board, eta_board, pt_board = get_predictions_board(X_test, model_name + '.onnx', imgs_per_cluster=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_python = np.stack((delta_phi_python, delta_eta_python, delta_pt_python)).T\n",
    "res_board = np.stack((phi_board, eta_board, pt_board)).T\n",
    "\n",
    "print(res_python)\n",
    "print(res_board.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_scaler = joblib.load('integer_scouting_7_4_2020_3layers_Y_scaler.dat')\n",
    "Y_python_rescaled = Y_scaler.inverse_transform(res_python)\n",
    "Y_board_rescaled = Y_scaler.inverse_transform(res_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('7_4_2020_scout_output_python.csv', Y_python_rescaled[:204000], delimiter=',')\n",
    "np.savetxt('7_4_2020_scout_output_board.csv', Y_board_rescaled, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
